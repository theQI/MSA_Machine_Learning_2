{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant('Hello World!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRAIN_SIZE(num):\n",
    " print ('Total Training Images in Dataset = ' +\n",
    "str(mnist.train.images.shape))\n",
    " print ('--------------------------------------------------')\n",
    " x_train = mnist.train.images[:num,:]\n",
    " print ('x_train Examples Loaded = ' + str(x_train.shape))\n",
    " y_train = mnist.train.labels[:num,:]\n",
    " print ('y_train Examples Loaded = ' + str(y_train.shape))\n",
    " print('')\n",
    " return x_train, y_train\n",
    "def TEST_SIZE(num):\n",
    " print ('Total Test Examples in Dataset = ' +\n",
    "str(mnist.test.images.shape))\n",
    " print ('--------------------------------------------------')\n",
    " x_test = mnist.test.images[:num,:]\n",
    " print ('x_test Examples Loaded = ' + str(x_test.shape))\n",
    " y_test = mnist.test.labels[:num,:]\n",
    " print ('y_test Examples Loaded = ' + str(y_test.shape))\n",
    " return x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random as ran\n",
    "import numpy as np\n",
    "def display_digit(num):\n",
    " print(y_train[num])\n",
    " label = y_train[num].argmax(axis=0)\n",
    " image = x_train[num].reshape([28,28])\n",
    " plt.title('Example: %d Label: %d' % (num, label))\n",
    " plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    " plt.show()\n",
    "def display_mult_flat(start, stop):\n",
    " images = x_train[start].reshape([1,784])\n",
    " for i in range(start+1,stop):\n",
    "     images = np.concatenate((images, x_train[i].reshape([1,784])))\n",
    "     plt.imshow(images, cmap=plt.get_cmap('gray_r'))\n",
    "     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Images in Dataset = (55000, 784)\n",
      "--------------------------------------------------\n",
      "x_train Examples Loaded = (55000, 784)\n",
      "y_train Examples Loaded = (55000, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = TRAIN_SIZE(55000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Test Examples in Dataset = (10000, 784)\n",
      "--------------------------------------------------\n",
      "x_test Examples Loaded = (10000, 784)\n",
      "y_test Examples Loaded = (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = TEST_SIZE(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_digit(ran.randint(0, x_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# Input and output\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784]) # input image 28*28 = 784\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10]) #0-9 digits (10 classes)\n",
    "# Model parameters\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y),\n",
    "reduction_indices=[1]))\n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step:0 Accuracy = 0.6705 Loss = 2.1970637\n",
      "Training Step:100 Accuracy = 0.8713 Loss = 0.6085837\n",
      "Training Step:200 Accuracy = 0.8857 Loss = 0.49071002\n"
     ]
    }
   ],
   "source": [
    "TRAIN_STEPS = 250\n",
    "for i in range(TRAIN_STEPS+1):\n",
    " sess.run(training, feed_dict={x: x_train, y_: y_train})\n",
    " if i%100 == 0:\n",
    "        print('Training Step:' + str(i) + ' Accuracy = ' +str(sess.run(accuracy, feed_dict={x: x_test, y_: y_test})) + ' Loss = ' + str(sess.run(cross_entropy, {x: x_train, y_: y_train})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784]) # input image 28*28 = 784\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, 10]) #0-9 digits (10 classes)\n",
    "# Two hidden layers, output layer and their number of neurons (the last layer has 10 softmax neurons)\n",
    "L = 100\n",
    "M = 30\n",
    "# tf.truncated_normal is a TensorFlow function that produces random values following the normal (Gaussian) distribution between -2*stddev and +2*stddev\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1)) # 784 = 28 * 28\n",
    "B1 = tf.Variable(tf.zeros([L]))\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
    "B2 = tf.Variable(tf.zeros([M]))\n",
    "W3 = tf.Variable(tf.truncated_normal([M, 10], stddev=0.1))\n",
    "B3 = tf.Variable(tf.zeros([10]))\n",
    "# The model\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "Y1 = tf.nn.sigmoid(tf.matmul(XX, W1) + B1)\n",
    "Y2 = tf.nn.sigmoid(tf.matmul(Y1, W2) + B2)\n",
    "Ylogits = tf.matmul(Y2, W3) + B3\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-cf3637ac3ee8>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross-entropy loss function (= -sum(Y_i * log(Yi)) ), normalised for batches of 100 images\n",
    "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
    "# problems with log(0) which is NaN\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits,\n",
    "labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step:0 Accuracy = 0.1135 Loss = 230.05872\n",
      "Training Step:100 Accuracy = 0.7608 Loss = 91.249374\n",
      "Training Step:200 Accuracy = 0.8747 Loss = 47.874676\n",
      "Training Step:300 Accuracy = 0.9014 Loss = 36.56628\n",
      "Training Step:400 Accuracy = 0.9124 Loss = 31.516329\n",
      "Training Step:500 Accuracy = 0.9208 Loss = 28.062332\n",
      "Training Step:600 Accuracy = 0.9296 Loss = 25.254715\n",
      "Training Step:700 Accuracy = 0.935 Loss = 22.878113\n",
      "Training Step:800 Accuracy = 0.9408 Loss = 20.860199\n",
      "Training Step:900 Accuracy = 0.9448 Loss = 19.143814\n",
      "Training Step:1000 Accuracy = 0.9486 Loss = 17.67248\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y),reduction_indices=[1]))\n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "#correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "TRAIN_STEPS = 1000\n",
    "for i in range(TRAIN_STEPS+1):\n",
    " sess.run(training, feed_dict={X: x_train, Y_: y_train})\n",
    " if i%100 == 0:\n",
    "  print('Training Step:' + str(i) + ' Accuracy = ' + str(sess.run(accuracy, feed_dict={X: x_test, Y_: y_test})) + ' Loss = ' + str(sess.run(cross_entropy, {X: x_train, Y_: y_train})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-e99b0634e8cc>:21: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Drop Out\n",
    "\n",
    "# Input and output\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784]) # input image 28*28 = 784\n",
    "Y_ = tf.placeholder(tf.float32, shape=[None, 10]) #0-9 digits (10 classes)\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "L = 100\n",
    "M = 30\n",
    "N = 60\n",
    "O = 30\n",
    "# tf.truncated_normal is a TensorFlow function that produces random values following the normal (Gaussian) distribution between -2*stddev and +2*stddev\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1)) # 784 = 28 * 28\n",
    "B1 = tf.Variable(tf.ones([L])/10)\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
    "B2 = tf.Variable(tf.ones([M])/10)\n",
    "W3 = tf.Variable(tf.truncated_normal([M, 10], stddev=0.1))\n",
    "B3 = tf.Variable(tf.zeros([10]))\n",
    "# The model\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "Y1 = tf.nn.relu(tf.matmul(XX, W1) + B1)\n",
    "Y1d = tf.nn.dropout(Y1, pkeep)\n",
    "Y2 = tf.nn.relu(tf.matmul(Y1, W2) + B2)\n",
    "Y2d = tf.nn.dropout(Y2, pkeep)\n",
    "Ylogits = tf.matmul(Y2d, W3) + B3\n",
    "Y = tf.nn.softmax(Ylogits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step:0 Accuracy = 0.276 Loss = 221.87068\n",
      "Training Step:100 Accuracy = 0.9109 Loss = 36.924397\n",
      "Training Step:200 Accuracy = 0.9452 Loss = 22.292372\n",
      "Training Step:300 Accuracy = 0.9554 Loss = 17.025251\n",
      "Training Step:400 Accuracy = 0.9626 Loss = 13.69154\n",
      "Training Step:500 Accuracy = 0.9684 Loss = 11.143867\n",
      "Training Step:600 Accuracy = 0.9705 Loss = 9.514872\n",
      "Training Step:700 Accuracy = 0.9729 Loss = 8.109653\n",
      "Training Step:800 Accuracy = 0.9733 Loss = 7.490014\n",
      "Training Step:900 Accuracy = 0.9734 Loss = 6.5966167\n",
      "Training Step:1000 Accuracy = 0.9525 Loss = 19.962326\n"
     ]
    }
   ],
   "source": [
    "# cross-entropy loss function (= -sum(Y_i * log(Yi)) ), normalised for batches of 100 images\n",
    "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
    "# problems with log(0) which is NaN\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits,\n",
    "labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "LEARNING_RATE = 0.01\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y),reduction_indices=[1]))\n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "#correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "TRAIN_STEPS = 1000\n",
    "for i in range(TRAIN_STEPS+1):\n",
    " sess.run(training, feed_dict={X: x_train, Y_: y_train, pkeep: 0.75 })\n",
    " if i%100 == 0:\n",
    "  print('Training Step:' + str(i) + ' Accuracy = ' + str(sess.run(accuracy, feed_dict={X: x_test, Y_: y_test, pkeep: 1.0})) + ' Loss = ' + str(sess.run(cross_entropy, {X: x_train, Y_: y_train , pkeep: 0.75})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
